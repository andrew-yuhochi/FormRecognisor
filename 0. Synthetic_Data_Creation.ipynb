{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83d7688-7444-46b9-9cfa-ee663e48cb8d",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b08f76c4-efc7-4065-bd3b-7a1f4d6ebb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "import imageio\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8caff7-7c75-4c7b-867b-c4ba0ed89c90",
   "metadata": {},
   "source": [
    "### 1. Create Synthetic Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473e7eb2-5ee1-4d36-995c-df21630edccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trasnform(image):\n",
    "    \"\"\"\n",
    "    Input an array of images, go through effect-related augmentation, then return back the array of images\n",
    "    \"\"\"\n",
    "    # Below effects will be added to all images sequentially with randomised degree, normal distribution, details please refer to imgaug library\n",
    "    p = iaa.Sequential([\n",
    "        iaa.CropAndPad(percent=iap.Normal(0, 0.02)),\n",
    "        iaa.Affine(scale = {\"x\": iap.Normal(1, 0.015), \"y\": iap.Normal(1, 0.015)}),\n",
    "        iaa.Affine(translate_percent = {\"x\": iap.Normal(0, 0.015), \"y\": iap.Normal(0, 0.015)}),\n",
    "        iaa.Affine(rotate = iap.Normal(0, 3)),\n",
    "        iaa.Affine(shear = {\"x\": iap.Normal(0, 0.5), \"y\": iap.Normal(0, 0.5)}),\n",
    "        iaa.AddToHueAndSaturation(value= iap.Normal(0, 20), per_channel = True),\n",
    "        iaa.AddToBrightness(add = iap.Normal(0, 50)),\n",
    "        iaa.GammaContrast(gamma = (0.2,1.5))   \n",
    "    ], random_order=True)\n",
    "    \n",
    "    # Some of the below effects would be added to images with with randomised degree\n",
    "    e = iaa.SomeOf((0, None), [\n",
    "        iaa.GaussianBlur(sigma = iap.ChiSquare(2)),\n",
    "        iaa.AdditiveGaussianNoise(scale=(0, 0.1*255)),\n",
    "        iaa.ElasticTransformation(alpha=(0, 2.5), sigma=(0.25, 1)),\n",
    "        iaa.Cutout(nb_iterations = (1, 3), size = (0.02, 0.07), fill_mode=\"gaussian\", fill_per_channel=True)\n",
    "    ], random_order=True)\n",
    "    \n",
    "    # Resize image to 1024 x 768 to ensure it fit to our designed network input\n",
    "    r = iaa.Resize({\"height\": 1024, \"width\": 768})\n",
    "    \n",
    "    image = p(image=image)\n",
    "    image = e(image=image)\n",
    "    image = r(image=image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80c1390f-4d60-4c5c-bb85-8bad7cdc97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(load_dir, save_dir, num_of_syn = None, train_val_test_ratio = None):\n",
    "    '''input the load and save directory, the number of synthetic to be created and a list of train, validation and test ratio, i.e. [0.6, 0.2, 0.2], perform the synthetic creation and save into the saving directory.'''\n",
    "    \n",
    "    # handling None input value and check input validation of train_val_test_ratio\n",
    "    if train_val_test_ratio == None:\n",
    "        train_val_test_ratio = [0.6, 0.2, 0.2]\n",
    "    if sum(train_val_test_ratio) != 1:\n",
    "        print(\"Error! the sum of dataset ratio is not equal to 1\")\n",
    "        return \n",
    "    if num_of_syn == None:\n",
    "        num_of_syn = 200\n",
    "    \n",
    "    # save a list of images name\n",
    "    raw_data_list = os.listdir(load_dir)\n",
    "    \n",
    "    # removve ipynb checkpoint from the list if any\n",
    "    while (raw_data_list[0] == '.ipynb_checkpoints')|(raw_data_list[0] == '.DS_Store'):\n",
    "        raw_data_list = raw_data_list[1:]\n",
    "    raw_data_list.sort()\n",
    "    \n",
    "    k = 0\n",
    "    current_classes = \"nothing\"\n",
    "    test_path = save_dir +  \"/test/test\" \n",
    "    os.makedirs(test_path)\n",
    "    \n",
    "    \n",
    "    # loop through all raw data and perform synthetic transformation\n",
    "    for i in raw_data_list:\n",
    "        now = datetime.now()\n",
    "        \n",
    "        classes = i[:5]\n",
    "        \n",
    "        if classes != current_classes:\n",
    "            train_path = save_dir +  \"/train/\" + classes\n",
    "            val_path = save_dir +  \"/validation/\" + classes\n",
    "            os.makedirs(train_path)\n",
    "            os.makedirs(val_path)\n",
    "            current_classes = classes\n",
    "        \n",
    "        \n",
    "        img = load_dir + \"/\" + i\n",
    "        img = imageio.imread(img)\n",
    "        images = [trasnform(img) for _ in range(num_of_syn)]\n",
    "        \n",
    "        # create an array to indicate which dataset (train/validation/test) belong to each created image.\n",
    "        train, test = train_test_split(np.linspace(0, num_of_syn, num=num_of_syn, endpoint=False).astype(int), \n",
    "                                   test_size=train_val_test_ratio[2])\n",
    "        train, val = train_test_split(train, test_size = train_val_test_ratio[1]/(train_val_test_ratio[0] + train_val_test_ratio[1]))\n",
    "        \n",
    "        idx = np.repeat(0, num_of_syn)\n",
    "        idx[train] = 1\n",
    "        idx[val] = 2\n",
    "        idx[test] = 3\n",
    "        \n",
    "        # load through all created image and define the saved link.\n",
    "        for j in range(num_of_syn):\n",
    "            if idx[j] == 1:\n",
    "                saved_path = train_path\n",
    "            elif idx[j] == 2:\n",
    "                saved_path = val_path\n",
    "            else:\n",
    "                saved_path = test_path\n",
    "            \n",
    "            # find the correct item number to be saved\n",
    "            saved_img_list = os.listdir(saved_path)\n",
    "            rank = len(saved_img_list) + 1 \n",
    "            \n",
    "            save_path = saved_path + \"/\" + classes + \"_\" + str(rank) + \".jpeg\"\n",
    "            \n",
    "            imageio.imwrite(save_path, images[j])\n",
    "    \n",
    "        k = k+1\n",
    "        if k % 10 == 9:\n",
    "            print(\"Finished\", k+1, \"images transformation, used\", datetime.now()-now,\"from pervious checking point.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ee7ec27-aa36-402c-9ec0-b337bb6f1811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10 images transformation, used 0:04:33.226601 from pervious checking point.\n",
      "Finished 20 images transformation, used 0:04:30.123661 from pervious checking point.\n",
      "Finished 30 images transformation, used 0:02:36.083978 from pervious checking point.\n",
      "Finished 40 images transformation, used 0:02:29.762521 from pervious checking point.\n",
      "Finished 50 images transformation, used 0:02:23.570362 from pervious checking point.\n",
      "Finished 60 images transformation, used 0:02:16.030326 from pervious checking point.\n",
      "Finished 70 images transformation, used 0:02:22.032877 from pervious checking point.\n",
      "Finished 80 images transformation, used 0:02:28.979680 from pervious checking point.\n",
      "Finished 90 images transformation, used 0:02:19.159746 from pervious checking point.\n",
      "Finished 100 images transformation, used 0:02:28.930212 from pervious checking point.\n",
      "Finished 110 images transformation, used 0:02:18.317539 from pervious checking point.\n",
      "Finished 120 images transformation, used 0:02:30.141957 from pervious checking point.\n",
      "Finished 130 images transformation, used 0:02:18.693031 from pervious checking point.\n",
      "Finished 140 images transformation, used 0:02:32.925612 from pervious checking point.\n",
      "Finished 150 images transformation, used 0:02:19.557238 from pervious checking point.\n",
      "Finished 160 images transformation, used 0:02:31.311108 from pervious checking point.\n",
      "Finished 170 images transformation, used 0:02:30.408970 from pervious checking point.\n",
      "Finished 180 images transformation, used 0:02:24.039365 from pervious checking point.\n",
      "Finished 190 images transformation, used 0:02:29.089128 from pervious checking point.\n",
      "Finished 200 images transformation, used 0:02:21.552619 from pervious checking point.\n",
      "Finished 210 images transformation, used 0:02:21.848249 from pervious checking point.\n",
      "Finished 220 images transformation, used 0:02:31.372884 from pervious checking point.\n",
      "Finished 230 images transformation, used 0:02:31.871930 from pervious checking point.\n",
      "Finished 240 images transformation, used 0:02:24.411281 from pervious checking point.\n",
      "Finished 250 images transformation, used 0:02:26.372944 from pervious checking point.\n",
      "Finished 260 images transformation, used 0:02:31.667379 from pervious checking point.\n"
     ]
    }
   ],
   "source": [
    "create_data(input_dir, synthetic_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2769d2-0a90-44ae-bbc7-f2fd4ec800b0",
   "metadata": {},
   "source": [
    "### 2. Create file directory fitted to Siamese Network. i.e. Anchor, Positive & Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d75047bd-c502-4641-b7d1-4cf4c35419d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 / 53 -th images of train data set has been performed, used 0:00:01.919996 time\n",
      "The 20 / 53 -th images of train data set has been performed, used 0:00:01.551921 time\n",
      "The 30 / 53 -th images of train data set has been performed, used 0:00:01.298729 time\n",
      "The 40 / 53 -th images of train data set has been performed, used 0:00:01.100435 time\n",
      "The 50 / 53 -th images of train data set has been performed, used 0:00:00.996069 time\n",
      "The 10 / 53 -th images of validation data set has been performed, used 0:00:00.716045 time\n",
      "The 20 / 53 -th images of validation data set has been performed, used 0:00:00.509220 time\n",
      "The 30 / 53 -th images of validation data set has been performed, used 0:00:00.477276 time\n",
      "The 40 / 53 -th images of validation data set has been performed, used 0:00:00.407891 time\n",
      "The 50 / 53 -th images of validation data set has been performed, used 0:00:00.306233 time\n"
     ]
    }
   ],
   "source": [
    "arr = os.listdir(synthetic_dir)\n",
    "arr.sort()\n",
    "\n",
    "for i in range(len(arr)):\n",
    "    ds = arr[i]\n",
    "    ds_dir = synthetic_dir + \"/\" + ds\n",
    "    classes = os.listdir(ds_dir)\n",
    "    classes.sort()\n",
    "    if classes[0] == '.ipynb_checkpoints':\n",
    "        classes = classes[1:]\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        \n",
    "        now = datetime.now()\n",
    "        \n",
    "        imgs_dir = ds_dir + \"/\" + classes[j]\n",
    "        imgs = os.listdir(imgs_dir) # a list of all images in the same classes\n",
    "        imgs.sort()\n",
    "        if imgs[0] == '.ipynb_checkpoints':\n",
    "            imgs = imgs[1:]\n",
    "        \n",
    "        if ds == \"test\":\n",
    "            anchor_dir = output_dir + \"/\" + ds + \"/\" + ds\n",
    "            os.makedirs(anchor_dir)\n",
    "        elif ds != \"test\":\n",
    "            \n",
    "            # Make directory only for train and validation set\n",
    "            anchor_dir = output_dir + \"/\" + ds + \"/anchor/\" + classes[j]\n",
    "            positive_dir = output_dir + \"/\" + ds + \"/positive/\" + classes[j]\n",
    "            negative_dir = output_dir + \"/\" + ds + \"/negative/\" + classes[j]\n",
    "            os.makedirs(anchor_dir)\n",
    "            os.makedirs(positive_dir)\n",
    "            os.makedirs(negative_dir)\n",
    "            \n",
    "            reorder_imgs = imgs.copy() \n",
    "            random.shuffle(reorder_imgs) # shuffle images in the same classes \n",
    "            other_classes = classes.copy() \n",
    "            other_classes.pop(j) # keep other classes\n",
    "            \n",
    "        for k in range(len(imgs)):\n",
    "            ori_path = imgs_dir + \"/\" + imgs[k]\n",
    "            if ds == \"test\":\n",
    "                save_path = anchor_dir + \"/\" + imgs[k]\n",
    "                copyfile(ori_path, save_path)\n",
    "            elif ds != \"test\":\n",
    "                # relocate the anchor \n",
    "                number_of_image_in_the_folder = str(len(os.listdir(anchor_dir))+1)\n",
    "                anchor_path = anchor_dir + \"/\" + number_of_image_in_the_folder + \".jpeg\"\n",
    "                copyfile(ori_path, anchor_path)\n",
    "                \n",
    "                # save the shuffled images as the positive sample for the anchor\n",
    "                ori_path = imgs_dir + \"/\" + reorder_imgs[k] \n",
    "                positive_path = positive_dir + \"/\" + number_of_image_in_the_folder + \".jpeg\"\n",
    "                copyfile(ori_path, positive_path)\n",
    "                \n",
    "                # randomly pick an image from another classes and save it as negative sample\n",
    "                pick_dir = ds_dir + \"/\" + random.choice(other_classes) \n",
    "                other_imgs = os.listdir(pick_dir)\n",
    "                other_imgs.sort()\n",
    "            \n",
    "                if other_imgs[0] == '.ipynb_checkpoints':\n",
    "                    other_imgs = other_imgs[1:]\n",
    "                \n",
    "                ori_path = pick_dir + \"/\" + random.choice(other_imgs)\n",
    "                negative_path = negative_dir + \"/\" + number_of_image_in_the_folder + \".jpeg\"\n",
    "                copyfile(ori_path, negative_path)\n",
    "                \n",
    "        #report time taken\n",
    "        if j % 10 == 9:\n",
    "            print(\"The\", j+1, \"/\", len(classes), \"-th images of\", arr[i], \"data set has been performed, used\", datetime.now()-now,\"time\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58dbe5-2192-447d-96d1-82472659ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
